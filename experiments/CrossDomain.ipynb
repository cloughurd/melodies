{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BagOfNotes, BagOfChords2, NfIsf, PreprocessMidiDataFrame, MidiPathToDataFrame, MidiPathToPrettyMidi,InstrumentAwareBoN\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevaluation\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path('../src').resolve()))\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import clone\n",
    "from preprocessing import BagOfNotes, BagOfChords2, NfIsf, PreprocessMidiDataFrame, MidiPathToDataFrame, MidiPathToPrettyMidi,InstrumentAwareBoN\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maestro_path = Path('../maestro/maestro-v3.0.0/')\n",
    "df = pd.read_csv('../eda/no_dups.csv')\n",
    "train = df[df.split == 'train']\n",
    "validate = df[df.split == 'validation']\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('loader', MidiPathToDataFrame(maestro_path)),\n",
    "    ('cleaner', PreprocessMidiDataFrame()),\n",
    "])\n",
    "train_loaded = pipe.transform(train.midi_filename)\n",
    "val_loaded = pipe.transform(validate.midi_filename)\n",
    "\n",
    "pretty_train = MidiPathToPrettyMidi(maestro_path).transform(train.midi_filename)\n",
    "pretty_val = MidiPathToPrettyMidi(maestro_path).transform(validate.midi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitmidi_folder = Path('../data/')\n",
    "bitmidi_files = [f for f in os.listdir(bitmidi_folder) if f.endswith(\".mid\")]\n",
    "bitmidi_raw = Pipeline([\n",
    "    ('loader', MidiPathToDataFrame(bitmidi_folder)),\n",
    "    ('cleaner', PreprocessMidiDataFrame())\n",
    "]).transform(bitmidi_files)\n",
    "bitmidi_pretty = MidiPathToPrettyMidi(bitmidi_folder).transform(bitmidi_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [\n",
    "    ('BoN', BagOfNotes(normalize=False)),\n",
    "    ('BoNn', BagOfNotes(normalize=True)),\n",
    "    ('NfIsf', NfIsf()),\n",
    "    ('BoC2', BagOfChords2(time_threshold=30)),\n",
    "    ('InstBoN', InstrumentAwareBoN())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec_test = BagOfNotes(normalize=True).fit_transform(midi_dfs)\n",
    "scores = {}\n",
    "for n in range(3, 36, 3):\n",
    "    iso = Isomap(n_neighbors=n, n_components=2)\n",
    "    X_iso = iso.fit_transform(X_vec_test)\n",
    "    kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_iso)\n",
    "    scores[n] = silhouette_score(X_iso, labels)\n",
    "    print(f\"n_neighbors={n}, silhouette={scores[n]:.4f}\")\n",
    "best_n = max(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iso = Isomap(n_neighbors=best_n, n_components=2).fit_transform(X_vec_test)\n",
    "k_scores = {}\n",
    "for k in range(2, 31):\n",
    "    labels = KMeans(n_clusters=k, random_state=42).fit_predict(X_iso)\n",
    "    k_scores[k] = silhouette_score(X_iso, labels)\n",
    "    print(f\"k={k}, silhouette={k_scores[k]:.4f}\")\n",
    "best_k = max(k_scores, key=k_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducers = [\n",
    "    ('PCA2', PCA(n_components=2)),\n",
    "    ('Iso2', Isomap(n_neighbors=best_n, n_components=2)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterers = [\n",
    "    ('kmeans', KMeans(n_clusters=best_k, random_state=33))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "bitmidi_cluster_results = {}\n",
    "\n",
    "for vec_name, vectorizer in vectorizers:\n",
    "    maestro_data = pretty_train if vec_name == 'InstBoN' else train_loaded\n",
    "    val_data = pretty_val if vec_name == 'InstBoN' else val_loaded\n",
    "    bitmidi_data = bitmidi_pretty if vec_name == 'InstBoN' else bitmidi_raw\n",
    "\n",
    "    for red_name, reducer in reducers:\n",
    "        for clust_name, clusterer in clusterers:\n",
    "            print(f'Running: {vec_name}-{red_name}-{clust_name}')\n",
    "            model = Pipeline([\n",
    "                (vec_name, vectorizer),\n",
    "                (red_name, reducer),\n",
    "                (clust_name, clusterer)\n",
    "            ])\n",
    "            model = clone(model)\n",
    "\n",
    "            try:\n",
    "                model.fit(maestro_data)\n",
    "                val_embeddings = model[:2].transform(val_data)\n",
    "                val_preds = model.named_steps[clust_name].predict(val_embeddings)\n",
    "                score = evaluation.evaluate_clusters(val_preds, validate[['canonical_composer']])\n",
    "\n",
    "                key = f'{vec_name}-{red_name}-{clust_name}'\n",
    "                results[key] = score\n",
    "\n",
    "                bitmidi_embeds = model[:2].transform(bitmidi_data)\n",
    "                bitmidi_clusters = model.named_steps[clust_name].predict(bitmidi_embeds)\n",
    "                bitmidi_cluster_results[key] = bitmidi_clusters\n",
    "\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.scatter(val_embeddings[:, 0], val_embeddings[:, 1], alpha=0.5, label='MAESTRO Val')\n",
    "                plt.scatter(bitmidi_embeds[:, 0], bitmidi_embeds[:, 1], c='red', marker='x', label='BitMidi')\n",
    "                plt.title(f\"{key} Embedding\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {key}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_key = max(results, key=lambda k: results[k]['silhouette'])\n",
    "print(f\"Best model: {best_model_key}\")\n",
    "best_model = Pipeline([\n",
    "    vectorizers[[v[0] for v in vectorizers].index(best_model_key.split('-')[0])][1],\n",
    "    reducers[[r[0] for r in reducers].index(best_model_key.split('-')[1])][1]\n",
    "])\n",
    "X_embed = best_model.fit_transform(midi_dfs)\n",
    "plt.scatter(X_embed[:, 0], X_embed[:, 1], c=dedupe.canonical_composer.astype('category').cat.codes)\n",
    "plt.title('MAESTRO Cluster Embedding')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmelodies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
